{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colorization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/SNU\")"
      ],
      "metadata": {
        "id": "HFxeoRGeuRBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4Hvwy1XGOBB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from __future__ import print_function\n",
        "import itertools\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from data import get_trn_loader, get_val_loader, get_test_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')"
      ],
      "metadata": {
        "id": "Rp7osbWtuO0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_loader, val_loader, test_loader = get_trn_loader(), get_val_loader(), get_test_loader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H8cZQSbuhN9",
        "outputId": "3a9a0645-0316-405b-fd7c-d67645084917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def toYUV(rgb):\n",
        "    rgb = rgb.numpy()\n",
        "    R, G, B = rgb[0, :, :], rgb[1, :, :], rgb[2, :, :]\n",
        "    Y = 0.299 * R + 0.587 * G + 0.114 *B\n",
        "    U = -0.147 * R + -0.289 * G + 0.436 * G\n",
        "    V = 0.615 * R + -0.515 * G - 0.100 * B\n",
        "    return torch.from_numpy(np.asarray([Y, U, V]).reshape(3, 64, 64))\n",
        "    \n",
        "def toRGB(yuv, batchsize):\n",
        "    \"\"\"shape of yuv is bs x 3 x 64 x 64, ordered by YUV\"\"\"\n",
        "    lst = []\n",
        "    for data in yuv:\n",
        "        Y, U, V = data[0, :, :], data[1, :, :], data[2, :, :]\n",
        "        R = Y + 1.140 * V\n",
        "        G = Y + (-0.395 * U) + (-0.581 * V)\n",
        "        B = Y + 2.032 * U\n",
        "        lst.append([R,G,B])\n",
        "    return np.asarray(lst).reshape(batchsize, 3, 64, 64)#.clip(0, 255)"
      ],
      "metadata": {
        "id": "_ZIRmpimGsyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extractGray(batchSize, yuv):\n",
        "    lst = []\n",
        "    for data in yuv:\n",
        "        lst.append(data[0])\n",
        "    return np.asarray(lst).reshape(batchSize, 1, 64, 64)"
      ],
      "metadata": {
        "id": "8I41jZkBG7LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Discriminator"
      ],
      "metadata": {
        "id": "SVQwRqxDHBl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _netD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_netD, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            # 3 x 64 x 64\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 64 x 32 x 32\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 128 x 16 x 16\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 256 x 8 x 8\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "\n",
        "            # 512 x 4 x 4\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512 * 4 * 4, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        # input is real or fake colored image\n",
        "        x = self.cnn(input)\n",
        "        x = x.view(x.size(0), 512 * 4 * 4) # flatten it\n",
        "        output = self.fc(x)\n",
        "        return output.view(-1,1).squeeze(1)"
      ],
      "metadata": {
        "id": "Hnckano0G_Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ],
      "metadata": {
        "id": "g4OH2h-lHDOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _netG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_netG, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(100, 1 * 64 * 64)\n",
        "        self.conv1 = nn.Conv2d(2, 130, 3, 1, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(130)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(132, 66, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(66)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(68, 65, 3, 1, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(65)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(66, 65, 3, 1, 1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(65)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(66, 33, 3, 1, 1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(33)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(34, 2, 3, 1, 1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    def forward(self, input, noise_pure):\n",
        "        # input is grayscale image(Y of YUV), noise is random sampled noise\n",
        "        noise = self.fc(noise_pure)\n",
        "        noise = noise.view(noise.size(0), 1, 64, 64)\n",
        "\n",
        "        # 2 x 64 x 64\n",
        "        x = self.conv1(torch.cat([input, noise], dim=1))\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # 130 x 64 x 64\n",
        "        input2 = torch.cat([input, x ,noise], dim=1)\n",
        "        # 132 x 64 x 64\n",
        "        x = self.conv2(input2)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # 66 x 64 x 64\n",
        "        input3 = torch.cat([input, x, noise], dim=1)\n",
        "        # 68 x 64 x 64\n",
        "        x = self.conv3(input3)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # 65 x 64 x 64\n",
        "        input4 = torch.cat([input, x], dim=1)\n",
        "        # 66 x 64 x 64\n",
        "        x = self.conv4(input4)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # 65 x 64 x 64\n",
        "        input5 = torch.cat([input, x], dim=1)\n",
        "        # 66 x 64 x 64\n",
        "        x = self.conv5(input5)\n",
        "        x = self.bn5(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # 33 x 64 x 64\n",
        "        input6 = torch.cat([input, x], dim=1)\n",
        "        # 34 x 64 x 64\n",
        "        x = self.conv6(input6)\n",
        "\n",
        "        output = torch.cat([input, x], dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "EMXPL2XIHGcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:         # Conv weight init\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "netG = _netG().cuda()\n",
        "netG.apply(weights_init)\n",
        "print(netG)\n",
        "\n",
        "netD = _netD().cuda()\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "metadata": {
        "id": "SRjVfZM1HLnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff9a867-df01-444c-a53d-d685b11aa808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_netG(\n",
            "  (fc): Linear(in_features=100, out_features=4096, bias=True)\n",
            "  (conv1): Conv2d(2, 130, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(132, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(68, 65, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(66, 65, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn4): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(66, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn5): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv6): Conv2d(34, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "_netD(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=8192, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss().cuda()\n",
        "batchSize = 32\n",
        "\n",
        "\n",
        "input = torch.FloatTensor(batchSize, 3, 64, 64).cuda()\n",
        "noise = torch.FloatTensor(batchSize, 100).cuda()\n",
        "\n",
        "label = torch.FloatTensor(batchSize).cuda()\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0002,betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002,betas=(0.5, 0.999))\n",
        "result_dict= {}\n",
        "loss_D, loss_G = [], []"
      ],
      "metadata": {
        "id": "EauJpqKKHPTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outf= '/content/drive/MyDrive/SNU/CNN_distortion/result'\n",
        "\n",
        "for epoch in range(1,300):\n",
        "    for i, (data, _) in enumerate(trn_loader):\n",
        "        data = data.cuda()\n",
        "        batchSize = len(data)\n",
        "        gray = extractGray(batchSize, data.cpu().numpy())\n",
        "        grayv = Variable(torch.from_numpy(gray)).cuda()\n",
        "        #############\n",
        "        # D!        #\n",
        "        #############\n",
        "        netD.zero_grad()\n",
        "        ##############\n",
        "        # real image #\n",
        "        ##############\n",
        "        input.resize_as_(data).copy_(data)\n",
        "        label.resize_(len(data)).fill_(real_label)\n",
        "\n",
        "        inputv = Variable(input).cuda()\n",
        "        labelv = Variable(label).cuda()\n",
        "\n",
        "        output = netD(inputv)\n",
        "        errD_real = criterion(output, labelv)\n",
        "        errD_real.backward()\n",
        "        D_x = output.data.mean()\n",
        "\n",
        "        ##############\n",
        "        # fake image #\n",
        "        ##############\n",
        "        noise.resize_(batchSize, 100).uniform_(0,1)\n",
        "        noisev = Variable(noise).cuda()\n",
        "\n",
        "        # create fake images\n",
        "        fake = netG(grayv, noisev)\n",
        "\n",
        "        # cal loss\n",
        "        output = netD(fake.detach())\n",
        "        labelv = Variable(label.fill_(fake_label)).cuda()\n",
        "        errD_fake = criterion(output, labelv)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.data.mean()\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ##############\n",
        "        # G!         #\n",
        "        ##############\n",
        "        netG.zero_grad()\n",
        "        labelv = Variable(label.fill_(real_label)).cuda()\n",
        "        output = netD(fake)\n",
        "\n",
        "        errG = criterion(output, labelv)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.data.mean()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if ((i+1) % 100 == 0):\n",
        "            if not os.path.exists('results/'):\n",
        "                os.makedirs('results/')\n",
        "            rgb = toRGB(fake.cpu().data.numpy(), batchSize)\n",
        "            vutils.save_image(torch.from_numpy(rgb), '%s/fake_samples_epoch_%s.png' % (outf, str(epoch)+\" \"+str(i+1)))\n",
        "    print(epoch)\n",
        "    print(errD.data, errG.data)\n",
        "    rgb = toRGB(fake.cpu().data.numpy(), batchSize)\n",
        "    vutils.save_image(torch.from_numpy(rgb),'%s/fake_samples_epoch_%s.png' % (outf, epoch))\n",
        "    loss_D.append(errD.data)\n",
        "    loss_G.append(errG.data)\n",
        "    result_dict = {\"loss_D\":loss_D,\"loss_G\":loss_G}\n",
        "    pickle.dump(result_dict,open(\"{}/result_dict.p\".format(outf),\"wb\"))\n",
        "    # do checkpointing\n",
        "    torch.save(netG.state_dict(), '%s/netG.pth' % (outf))\n",
        "    torch.save(netD.state_dict(), '%s/netD.pth' % (outf))"
      ],
      "metadata": {
        "id": "RTcEfDIFHRj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb99a281-14a7-4344-ab9a-dc904fec1b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "tensor(0.2448, device='cuda:0') tensor(2.5188, device='cuda:0')\n",
            "2\n",
            "tensor(4.0196, device='cuda:0') tensor(6.0146, device='cuda:0')\n",
            "3\n",
            "tensor(2.1774, device='cuda:0') tensor(5.0486, device='cuda:0')\n",
            "4\n",
            "tensor(0.0406, device='cuda:0') tensor(5.6102, device='cuda:0')\n",
            "5\n",
            "tensor(0.9352, device='cuda:0') tensor(2.8675, device='cuda:0')\n",
            "6\n",
            "tensor(0.1135, device='cuda:0') tensor(3.6036, device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}
